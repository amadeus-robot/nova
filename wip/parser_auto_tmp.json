[{"code":"# Drop leading instance constraints – identical idea but we only\n  # need the remainder of the tokens (constraints are ignored for now).\n  defp drop_instance_constraints(tokens) do\n    {_before, after_} =\n      Enum.split_while(tokens, fn\n        %Token{type: :operator, value: \"<=\"} -> false\n        _ -> true\n      end)\n\n    case after_ do\n      [%Token{type: :operator, value: \"<=\"} | rest] -> rest\n      _ -> tokens\n    end\n  end","name":"drop_instance_constraints","description":"Drops tokens representing instance constraints in a type class instance declaration (e.g., `(C1, C2) <=`).\nIt splits the token list at the first occurrence of the \"<=\" operator and returns only the tokens *after* the \"<=\".\nReturns the list of tokens following the constraints (or the original list if no constraints are present). The constraints tokens are discarded.","deps":[]},{"code":"defp split_until_newline(tokens) do\n    Enum.split_while(tokens, fn\n      %Token{type: :newline} -> false\n      _ -> true\n    end)\n  end","name":"split_until_newline","description":"Splits a token list into two parts: tokens before the first newline, and tokens starting from that newline.\nReturns `{tokens_before_newline, tokens_starting_from_newline}`.","deps":[]},{"code":"defp split_type_and_rest(tokens, name) do\n    Enum.split_while(tokens, fn\n      %Token{type: :identifier, value: ^name} -> false\n      _ -> true\n    end)\n  end","name":"split_type_and_rest","description":"Splits a token list into two parts: tokens before an identifier matching a given name, and the tokens starting from that identifier.\nUsed to separate the type signature tokens from the function declaration tokens when parsing `name :: Type name parameters = body`.\nReturns `{tokens_before_name, tokens_starting_from_name}`.","deps":[]},{"code":"defp expect_colon([%Token{value: \":\"} | rest]), do: {:ok, \":\", rest}\n  defp expect_colon(_), do: {:error, \"Expected ':'\"}","name":"expect_colon","description":"Expects and consumes a colon token.\nReturns `{:ok, \":\", remaining_tokens}` if a colon is found, otherwise `{:error, reason}`.","deps":[]},{"code":"defp parse_separated(parser, separator, tokens) do\n    with {:ok, first, tokens} <- parser.(tokens) do\n      parse_separated_rest(parser, separator, tokens, [first])\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end\n\n  defp parse_separated_rest(parser, separator, tokens, acc) do\n    case separator.(tokens) do\n      {:ok, _, tokens} ->\n        case parser.(tokens) do\n          {:ok, item, rest} ->\n            parse_separated_rest(parser, separator, rest, [item | acc])\n\n          {:error, _} ->\n            {:error, \"Expected item after separator\"}\n        end\n\n      {:error, _} ->\n        # No more separators, we're done\n        {:ok, Enum.reverse(acc), tokens}\n    end\n  end","name":"parse_separated","description":"Parses a list of items separated by a specific separator.\nIt first parses the required first item using the `parser`, and then uses `parse_separated_rest` to parse subsequent items, expecting the `separator` parser between them.\nReturns `{:ok, list_of_items, remaining_tokens}` or an error tuple.","deps":[]},{"code":"# Helper to check if a token sequence likely starts a new pattern\n  defp is_pattern_start?(tokens) do\n    case tokens do\n      # Empty tokens can't start a pattern\n      [] -> false\n      # Number literals often start patterns\n      [%Token{type: :number} | _] -> true\n      # Identifiers often start patterns\n      [%Token{type: :identifier} | _] -> true\n      # Delimiters like (, [, { can start patterns\n      [%Token{type: :delimiter, value: v} | _] when v in [\"(\", \"[\", \"{\"] -> true\n      # String and char literals can be patterns\n      [%Token{type: :string} | _] -> true\n      [%Token{type: :char} | _] -> true\n      # Keywords that might terminate a case expression\n      [%Token{type: :keyword, value: val} | _] when val in [\"end\", \"in\", \"else\", \"then\"] -> true\n      # Otherwise it's not a pattern start\n      _ -> false\n    end\n  end","name":"is_pattern_start?","description":"Checks if the given token list likely starts a pattern.\nThis is a heuristic used in layout-aware parsing (like case bodies) to determine if a new line belongs to the current construct's body or starts a new clause/construct.\nIt checks the type and value of the first token.\nReturns `true` or `false`.","deps":[]},{"code":"defp strip_newlines(list),\n    do:\n      Enum.reject(list, fn\n        %Token{type: :newline} -> true\n        _ -> false\n      end)","name":"strip_newlines","description":"Removes all newline tokens from a list of tokens, regardless of their position.\nIt iterates through the list and keeps only tokens that are not of type `:newline`.\nReturns a new list containing only the non-newline tokens.","deps":[]},{"code":"defp skip_newlines(tokens) do\n    Enum.drop_while(tokens, fn %Token{type: t} -> t == :newline end)\n  end","name":"skip_newlines","description":"Skips any leading newline tokens from the input token list.\nIt iterates through the tokens and drops them as long as they are of type `:newline`.\nReturns the list of tokens starting from the first non-newline token, or an empty list if all tokens were newlines.","deps":[]},{"code":"def parse_wildcard_pattern([%Token{type: :identifier, value: \"_\"} | rest]),\n    do: {:ok, %Ast.Wildcard{}, rest}\n\n  def parse_wildcard_pattern(_), do: {:error, \"Expected wildcard\"}","name":"parse_wildcard_pattern","description":"Parses a wildcard pattern, represented by the identifier \"_\".\nReturns `{:ok, %Ast.Wildcard{}, remaining_tokens}` if \"_\" is found, otherwise `{:error, reason}`.","deps":[]},{"code":"defp skip_until_end(tokens) do\n    case Enum.find_index(tokens, fn token -> token.type == :keyword and token.value == \"end\" end) do\n      nil -> tokens\n      idx -> Enum.drop(tokens, idx + 1)\n    end\n  end","name":"skip_until_end","description":"Skips tokens until (and including) an \"end\" keyword is found.\nIt searches for the first token that is a `:keyword` with value `\"end\"`.\nIf found, it returns the list of tokens *after* this \"end\" keyword.\nIf not found, it returns the original list of tokens (meaning \"end\" was not present or already consumed).\nThis is used in `parse_do_block` to consume the trailing \"end\" of a do-block.","deps":[]},{"code":"# Skip superclass constraints in a `class` declaration – everything\n  # up to (and including) the first \"<=\" operator is treated as\n  # constraints and ignored for now. Returns `{rest, constraints_tokens}`.\n  defp skip_superclass_constraints(tokens) do\n    tokens = skip_newlines(tokens)\n\n    {before, after_} =\n      Enum.split_while(tokens, fn\n        %Token{type: :operator, value: \"<=\"} -> false\n        _ -> true\n      end)\n\n    case after_ do\n      [%Token{type: :operator, value: \"<=\"} | rest] -> {rest, before}\n      _ -> {tokens, []}\n    end\n  end","name":"skip_superclass_constraints","description":"Skips tokens representing superclass constraints in a type class declaration (e.g., `(C1, C2) <=`).\nIt splits the token list at the first occurrence of the \"<=\" operator.\nReturns a tuple `{remaining_tokens_after_constraints, tokens_representing_constraints}`. The constraints tokens are returned but currently ignored.","deps":["skip_newlines"]},{"code":"defp parse_literal(tokens) do\n    tokens = skip_newlines(tokens)\n\n    case tokens do\n      [%Token{type: :number, value: value} | rest] ->\n        {:ok, %Ast.Literal{type: :number, value: value}, rest}\n\n      [%Token{type: :string, value: value} | rest] ->\n        {:ok, %Ast.Literal{type: :string, value: value}, rest}\n\n      [%Token{type: :char, value: value} | rest] ->\n        {:ok, %Ast.Literal{type: :char, value: value}, rest}\n\n      _ ->\n        {:error, \"Expected literal\"}\n    end\n  end","name":"parse_literal","description":"Parses a literal value token (number, string, or char).\nIt skips leading newlines and checks the type of the first token.\nReturns `{:ok, %Ast.Literal{}, remaining_tokens}` or an error tuple if the token is not a recognized literal type.","deps":["skip_newlines"]},{"code":"defp expect_delimiter(tokens, expected) do\n    tokens = skip_newlines(tokens)\n\n    case tokens do\n      [%Token{type: :delimiter, value: ^expected} | rest] ->\n        {:ok, expected, rest}\n\n      _ ->\n        {:error, \"Expected delimiter '#{expected}'\"}\n    end\n  end","name":"expect_delimiter","description":"Expects and consumes a specific delimiter token.\nIt skips leading newlines and checks if the first token is a `:delimiter` with the expected value.\nReturns `{:ok, delimiter_value, remaining_tokens}` if the delimiter is found, otherwise `{:error, reason}`.","deps":["skip_newlines"]},{"code":"def expect_keyword(tokens, expected) do\n    tokens = skip_newlines(tokens)\n\n    case tokens do\n      [%Token{type: :keyword, value: ^expected} | rest] ->\n        {:ok, expected, rest}\n\n      _ ->\n        {:error, \"Expected keyword '#{expected}'\"}\n    end\n  end","name":"expect_keyword","description":"Expects and consumes a specific keyword token.\nIt skips leading newlines and checks if the first token is a `:keyword` with the expected value.\nReturns `{:ok, keyword_value, remaining_tokens}` if the keyword is found, otherwise `{:error, reason}`.","deps":["skip_newlines"]},{"code":"defp parse_label(tokens) do\n    tokens = skip_newlines(tokens)\n\n    case tokens do\n      [%Token{type: t, value: name} | rest] when t in [:identifier, :keyword] ->\n        {:ok, %Ast.Identifier{name: name}, rest}\n\n      _ ->\n        {:error, \"Expected label\"}\n    end\n  end","name":"parse_label","description":"Parses a label, which can be an identifier or a keyword.\nIt skips leading newlines and checks if the first token is an `:identifier` or `:keyword`.\nReturns `{:ok, %Ast.Identifier{} (representing the label name), remaining_tokens}` or an error tuple.","deps":["skip_newlines"]},{"code":"defp expect_operator(tokens, expected) do\n    tokens = skip_newlines(tokens)\n\n    case tokens do\n      [%Token{type: :operator, value: ^expected} | rest] ->\n        {:ok, expected, rest}\n\n      _ ->\n        {:error, \"Expected operator '#{expected}'\"}\n    end\n  end","name":"expect_operator","description":"Expects and consumes a specific operator token.\nIt skips leading newlines and checks if the first token is an `:operator` with the expected value.\nReturns `{:ok, operator_value, remaining_tokens}` if the operator is found, otherwise `{:error, reason}`.","deps":["skip_newlines"]},{"code":"defp parse_identifier(tokens) do\n    tokens = skip_newlines(tokens)\n\n    case tokens do\n      [%Token{type: :identifier, value: name} | rest] -> {:ok, %Ast.Identifier{name: name}, rest}\n      _ -> {:error, \"Expected identifier\"}\n    end\n  end","name":"parse_identifier","description":"Parses an identifier token.\nIt skips leading newlines and checks if the first token is an `:identifier`.\nReturns `{:ok, %Ast.Identifier{}, remaining_tokens}` or an error tuple.","deps":["skip_newlines"]},{"code":"defp ensure_consumed(rest) do\n    case skip_newlines(rest) do\n      [] ->\n        :ok\n\n      leftover ->\n        tok = hd(leftover)\n\n        {:error,\n         \"unexpected tokens after successful parse – \" <>\n           \"#{tok.type}:#{inspect(tok.value)} at line #{tok.line}, col #{tok.column}\"}\n    end\n  end","name":"ensure_consumed","description":"Checks if the entire token stream has been consumed after a parsing operation.\nIt skips any trailing newlines and then checks if the list is empty.\nReturns `:ok` if no tokens remain (after skipping newlines), otherwise returns an error tuple with details about the first unconsumed token.","deps":["skip_newlines"]},{"code":"defp parse_string_literal(tokens) do\n    tokens = skip_newlines(tokens)\n\n    case tokens do\n      [%Token{type: :string, value: value} | rest] -> {:ok, value, rest}\n      _ -> {:error, \"Expected string literal\"}\n    end\n  end","name":"parse_string_literal","description":"Parses a string literal token and returns its raw string value.\nIt skips leading newlines and checks if the first token is a `:string`.\nReturns `{:ok, string_value, remaining_tokens}` or an error tuple.","deps":["skip_newlines"]},{"code":"# as  <ident>\n  defp parse_import_alias([%Token{type: :identifier, value: \"as\"} | rest]) do\n    with {:ok, id, rest} <- parse_identifier(rest) do\n      {id.name, rest}\n    end\n  end\n\n  defp parse_import_alias(tokens), do: {nil, tokens}","name":"parse_import_alias","description":"Parses an optional \"as Alias\" clause in an import declaration.\nIf the tokens start with the identifier \"as\", it attempts to parse the following identifier as the alias.\nReturns `{alias_name, remaining_tokens}` where `alias_name` is the string or `nil` if no alias was present.","deps":["parse_identifier"]},{"code":"defp parse_constructors([%Token{type: :delimiter, value: \"(\"} | rest], mod) do\n    case rest do\n      [%Token{type: :operator, value: \".\"}, %Token{type: :operator, value: \".\"} | rest2] ->\n        {:ok, {mod, :all}, expect_delimiter(rest2, \")\") |> elem(2)}\n\n      [%Token{type: :operator, value: \"..\"} | rest2] ->\n        {:ok, {mod, :all}, expect_delimiter(rest2, \")\") |> elem(2)}\n\n      _ ->\n        with {:ok, ctors, rest2} <-\n               parse_separated(&parse_identifier/1, &expect_delimiter(&1, \",\"), rest),\n             {:ok, _, rest3} <- expect_delimiter(rest2, \")\") do\n          {:ok, {mod, Enum.map(ctors, & &1.name)}, rest3}\n        end\n    end\n  end","name":"parse_constructors","description":"Parses the parenthesized list of constructors following an identifier in an import item, like `(Ctor1, Ctor2)` or `(..)`.\nIt handles the special `(..)` syntax for importing all constructors and a comma-separated list of specific constructors.\nExpects the opening parenthesis to have already been consumed (or checked).\nReturns `{:ok, {module_name, list_of_constructors | :all}, remaining_tokens}`.","deps":["expect_delimiter","parse_separated","parse_identifier"]},{"code":"defp parse_qualified_identifier(tokens) do\n    parse_separated(&parse_identifier/1, &expect_operator(&1, \".\"), tokens)\n    |> case do\n      {:ok, parts, rest} when is_list(parts) ->\n        {:ok, %Ast.Identifier{name: Enum.map(parts, & &1.name) |> Enum.join(\".\")}, rest}\n\n      other ->\n        other\n    end\n  end","name":"parse_qualified_identifier","description":"Parses a qualified identifier, which is one or more identifiers separated by \".\".\nIt uses `parse_separated` with `parse_identifier` as the item parser and `expect_operator` for \".\".\nReturns `{:ok, %Ast.Identifier{} (with the full qualified name string), remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_identifier","expect_operator"]},{"code":"# Foo | Foo(..) | Foo(Bar,Baz)\n  defp parse_import_item(tokens) do\n    with {:ok, first, tokens} <- parse_identifier(tokens) do\n      case tokens do\n        [%Token{type: :delimiter, value: \"(\"} | _] ->\n          # keep the \"(\" so parse_constructors/2 matches its head clause\n          parse_constructors(tokens, first.name)\n\n        _ ->\n          {:ok, first.name, tokens}\n      end\n    end\n  end","name":"parse_import_item","description":"Parses a single item within an import list.\nAn item can be a simple identifier (e.g., `Foo`) or an identifier followed by a parenthesized list of constructors (e.g., `Foo(Bar, Baz)` or `Foo(..)`).\nIt first parses an identifier and then checks if it's followed by an opening parenthesis to handle the constructor list case.\nReturns `{:ok, item_representation, remaining_tokens}`.","deps":["parse_identifier","parse_constructors"]},{"code":"# \"(\" ImportList \")\"\n  defp parse_paren_import_list([%Token{type: :delimiter, value: \"(\"} | rest]) do\n    with {:ok, items, rest} <-\n           parse_separated(&parse_import_item/1, &expect_delimiter(&1, \",\"), rest),\n         {:ok, _, rest} <- expect_delimiter(rest, \")\") do\n      {:ok, items, rest}\n    end\n  end\n\n  defp parse_paren_import_list(_), do: {:error, \"no paren import list\"}","name":"parse_paren_import_list","description":"Parses a parenthesized list of import items, like `( Item1, Item2 )`.\nIt expects an opening parenthesis, uses `parse_separated` to parse items separated by commas, and expects a closing parenthesis.\nReturns `{:ok, list_of_items, remaining_tokens}` or `{:error, reason}` if the structure doesn't match.","deps":["parse_separated","parse_import_item","expect_delimiter"]},{"code":"#    (\"(\" … \")\" | \"hiding\" \"(\" … \")\" | ε)\n  defp parse_import_selectors([%Token{type: :identifier, value: \"hiding\"} | rest]) do\n    with {:ok, items, rest} <- parse_paren_import_list(rest) do\n      {:ok, items, true, rest}\n    end\n  end\n\n  defp parse_import_selectors(tokens) do\n    case parse_paren_import_list(tokens) do\n      {:ok, items, rest} -> {:ok, items, false, rest}\n      {:error, _} -> {:ok, [], false, tokens}\n    end\n  end","name":"parse_import_selectors","description":"Parses the optional part of an import declaration specifying which items to import or hide.\nIt looks for either `( Items )` or `hiding ( Items )`.\nIf neither is found, it assumes no selectors are specified.\nReturns `{:ok, list_of_items, is_hiding?, remaining_tokens}`.","deps":["parse_paren_import_list"]},{"code":"def clause_start?(tokens) do\n    # \"pattern  ->\"  without consuming the tokens\n    with {:ok, _pat, rest} <- parse_pattern(tokens),\n         {_, _guard, rest} <- maybe_parse_guard(rest),\n         {:ok, _arrow, _} <- expect_operator(rest, \"->\") do\n      true\n    else\n      _ -> false\n    end\n  end","name":"clause_start?","description":"Checks if the given token list starts with the pattern `pattern [ | guard ] ->`, without consuming the tokens.\nThis is used in layout-aware parsing to detect the start of a new case clause.\nIt attempts to parse a pattern, an optional guard, and expects \"->\".\nReturns `true` if the sequence matches, `false` otherwise.","deps":["parse_pattern","maybe_parse_guard","expect_operator"]},{"code":"# Helper function to collect all arguments for function application\n  defp collect_application_args([%Token{type: :newline} | rest], acc, base) do\n    rest = skip_newlines(rest)\n\n    case rest do\n      [%Token{column: col} | _] when col > base ->\n        case parse_term(rest) do\n          {:ok, arg, rest2} -> collect_application_args(rest2, acc ++ [arg], base)\n          # something else - abort\n          {:error, _} -> {acc, rest}\n        end\n\n      _ ->\n        # dedent or EOF → application ends\n        {acc, rest}\n    end\n  end\n\n  defp collect_application_args(tokens, acc, base) do\n    case parse_term(tokens) do\n      {:ok, arg, rest} -> collect_application_args(rest, acc ++ [arg], base)\n      {:error, _} -> {acc, tokens}\n    end\n  end","name":"collect_application_args","description":"Collects argument terms for a function application, respecting layout rules (arguments must be indented relative to the function term's starting column).\nIt recursively parses terms using `parse_term` as long as they are on the same line or indented on a new line relative to the base indentation.\nReturns `{list_of_argument_asts, remaining_tokens_after_arguments}`.","deps":["skip_newlines","parse_term","collect_application_args"]},{"code":"defp drop_newlines([%Token{type: :newline} | rest]), do: drop_newlines(rest)\n  defp drop_newlines(tokens), do: tokens","name":"drop_newlines","description":"Recursively drops any leading newline tokens from the input token list.\nThis is a simple recursive implementation of skipping leading newlines.\nReturns the list of tokens starting from the first non-newline token.","deps":["drop_newlines"]},{"code":"def maybe_parse_guard([%Token{type: :operator, value: \"|\"} | rest] = all) do\n    case IO.inspect(parse_expression(rest)) do\n      {:ok, guard_ast, rest} ->\n        {:ok, guard_ast, rest}\n\n      {:error, _} ->\n        {:error, nil, all}\n    end\n  end\n\n  def maybe_parse_guard(tokens), do: {:error, nil, tokens}","name":"maybe_parse_guard","description":"Attempts to parse an optional guard clause following a pattern, of the form `| expression`.\nIf the tokens start with \"|\", it parses the following expression as the guard.\nReturns `{:ok, guard_expression_ast, remaining_tokens}` if a guard is found and parsed successfully, or `{:error, nil, original_tokens}` if no guard is present or parsing fails.","deps":["parse_expression"]},{"code":"# ------------------------------------------------------------\n  # 4. additive (+ -)\n  # ------------------------------------------------------------\n  defp parse_additive_expression(tokens) do\n    with {:ok, left, tokens} <- parse_multiplicative_expression(tokens) do\n      case tokens do\n        [%Token{type: :operator, value: op} | rest] when op in [\"+\", \"-\", \"++\", \"<>\"] ->\n          with {:ok, right, rest} <- parse_additive_expression(rest) do\n            {:ok, %Ast.BinaryOp{op: op, left: left, right: right}, rest}\n          end\n\n        _ ->\n          {:ok, left, tokens}\n      end\n    end\n  end","name":"parse_additive_expression","description":"Parses expressions involving additive operators \"+\", \"-\", \"++\", \"<>\".\nIt parses the left side using `parse_multiplicative_expression` (higher precedence) and then, if an additive operator is found, recursively parses the right side using itself. Additive operators are right-associative.\nReturns `{:ok, expression_ast, remaining_tokens}`.","deps":["parse_multiplicative_expression","parse_additive_expression"]},{"code":"# Helpers\n  defp parse_any(parsers, tokens) do\n    case parsers do\n      [] ->\n        {:error, \"No parser succeeded #{inspect(List.first(tokens))}\"}\n\n      [parser | rest] ->\n        case parser.(tokens) do\n          {:ok, result, remaining} -> {:ok, result, remaining}\n          {:error, _} -> parse_any(rest, tokens)\n        end\n    end\n  end","name":"parse_any","description":"Tries a list of parsers in order on the given tokens.\nIt iterates through the provided parser functions and calls each one with the tokens.\nReturns the result of the first parser that returns an `{:ok, ...}` tuple, otherwise returns an `{:error, ...}` tuple if all parsers fail.","deps":["parse_any"]},{"code":"# Function application parsing\n  defp parse_application([%Token{column: base} | _] = toks) do\n    with {:ok, fn_term, rest} <- parse_term(toks) do\n      {args, rest} = collect_application_args(rest, [], base)\n\n      case args do\n        [] -> {:ok, fn_term, rest}\n        _ -> {:ok, %Ast.FunctionCall{function: fn_term, arguments: args}, new_rest} # Should be rest here?\n      end\n    end\n  end\n\n  defp parse_application([]) do\n    {:error, :no_tokens_remaining}\n  end","name":"parse_application","description":"Parses function application expressions, where a function term is followed by one or more argument terms.\nIt first parses the function term using `parse_term` and then uses `collect_application_args` to gather any following terms as arguments, respecting layout rules.\nReturns `{:ok, expression_ast (either the term itself or a %Ast.FunctionCall{}), remaining_tokens}` or an error tuple.","deps":["parse_term","collect_application_args"]},{"code":"# Modified to fix the application type parsing\n  defp parse_basic_type(tokens) do\n    case parse_qualified_identifier(tokens) do\n      {:ok, qid, rest} ->\n        # Gather any type arguments that follow the qualified name\n        case parse_many(&parse_type_atom/1, rest) do\n          {:ok, [], ^rest} ->\n            {:ok, qid, rest}\n\n          {:ok, args, new_rest} ->\n            {:ok, %Ast.FunctionCall{function: qid, arguments: args}, new_rest}\n        end\n\n      # fall back to the old rules\n      _ ->\n    case tokens do\n      [%Token{type: :identifier, value: name} | rest] ->\n        # Parse type arguments if any\n        case parse_many(&parse_type_atom/1, rest) do\n          {:ok, [], ^rest} ->\n            # No arguments, just an identifier\n            {:ok, %Ast.Identifier{name: name}, rest}\n\n          {:ok, args, new_rest} ->\n            # Type with arguments\n            {:ok, %Ast.FunctionCall{function: name, arguments: args}, new_rest}\n        end\n\n      [%Token{type: :delimiter, value: \"(\"} | rest] ->\n        with {:ok, type, rest} <- parse_type(rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \")\") do\n          {:ok, type, rest}\n        end\n\n      _ ->\n        {:error, \"Expected basic type\"}\n    end\n    end\n  end","name":"parse_basic_type","description":"Parses a basic type expression, which can be a qualified identifier (potentially followed by type arguments for type application), a simple identifier (potentially followed by type arguments), or a parenthesized type expression.\nIt first tries parsing a qualified identifier followed by type atoms. If that fails, it falls back to parsing a simple identifier followed by type atoms or a parenthesized type.\nReturns `{:ok, type_ast, remaining_tokens}` or an error tuple.","deps":["parse_qualified_identifier","parse_many","parse_type_atom","parse_identifier","parse_type","expect_delimiter"]},{"code":"# Binary expression parsing with precedence\n  # ------------------------------------------------------------\n  # 1. top-level binary-expression entry point\n  # ------------------------------------------------------------\n  defp parse_binary_expression(tokens) do\n    parse_any(\n      [\n        &parse_let_expression/1,\n        &parse_if_expression/1,\n        &parse_case_expression/1,\n        &parse_do_block/1,\n        &parse_lambda/1,\n        &parse_dollar_expression/1\n      ],\n      tokens\n    )\n  end","name":"parse_binary_expression","description":"The main entry point for parsing expressions, including those with binary operators and other top-level forms.\nIt tries parsing various expression types like let, if, case, do-blocks, lambda, and dollar application, using `parse_any`.\nReturns `{:ok, expression_ast, remaining_tokens}` or an error tuple if none succeed.","deps":["parse_any","parse_let_expression","parse_if_expression","parse_case_expression","parse_do_block","parse_lambda","parse_dollar_expression"]},{"code":"# ------------------------------------------------------------\n  #  Single binding  (accepts its own leading newline)\n  # ------------------------------------------------------------\n  def parse_binding(tokens) do\n    tokens = skip_newlines(tokens)\n\n    with {:ok, pat, tokens} <- parse_pattern(tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"=\"),\n         {:ok, rhs, tokens} <- parse_expression(tokens) do\n      {:ok, {pat, rhs}, tokens}\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end","name":"parse_binding","description":"Parses a single binding within a let expression, of the form `pattern = expression`.\nIt skips leading newlines, parses a pattern, expects \"=\", and parses the right-hand side expression.\nReturns `{:ok, {pattern_ast, expression_ast}, remaining_tokens}` or an error tuple.","deps":["skip_newlines","parse_pattern","expect_operator","parse_expression"]},{"code":"def parse_case_clause(tokens) do\n    tokens = skip_newlines(tokens)\n\n    # Record the left-edge column of this clause’s pattern\n    case tokens do\n      [] ->\n        {:error, \"no more to parse\"}\n\n      [%Token{column: indent} | _] ->\n        with {:ok, pattern, tokens} <- IO.inspect(parse_pattern(tokens)),\n             {_, guard, tokens} <- IO.inspect(maybe_parse_guard(tokens)),\n             {:ok, _, tokens} <- expect_operator(tokens, \"->\") do\n          {body_tokens, rest} = take_body(tokens, [], indent)\n\n          with {:ok, body, remaining} <- parse_expression(body_tokens),\n               [] <- skip_newlines(remaining) do\n            {:ok, %Ast.CaseClause{pattern: pattern, guard: guard, body: body},\n             drop_newlines(rest)}\n          else\n            {:error, reason} -> {:error, reason}\n            _ -> {:error, \"unexpected tokens after case-clause body\"}\n          end\n        end\n    end\n  end","name":"parse_case_clause","description":"Parses a single clause within a case expression, of the form `pattern [ | guard ] -> body`.\nIt skips leading newlines, parses the pattern, optionally parses a guard using `maybe_parse_guard`, expects \"->\", collects the body tokens based on indentation using `take_body`, parses the body expression, and checks for leftover tokens after the body.\nReturns `{:ok, %Ast.CaseClause{}, remaining_tokens}` or an error tuple.","deps":["skip_newlines","parse_pattern","maybe_parse_guard","expect_operator","take_body","parse_expression","drop_newlines"]},{"code":"# Parse case clauses recursively, collecting all clauses\n  def parse_case_clauses(tokens, expression, acc) do\n    # Try to parse a single case clause\n    case IO.inspect(parse_case_clause(tokens)) do\n      {:ok, clause, remaining} ->\n        # Successfully parsed a clause, continue with the remaining tokens\n        parse_case_clauses(remaining, expression, [clause | acc])\n\n      {:error, _} when acc != [] ->\n        # If parsing fails but we've already got some clauses, we're done\n        {:ok, %Ast.CaseExpression{expression: expression, cases: Enum.reverse(acc)}, tokens}\n\n      {:error, reason} ->\n        # If parsing fails and we have no clauses, propagate the error\n        {:error, reason}\n    end\n  end","name":"parse_case_clauses","description":"Recursively parses all clauses within a case expression.\nIt repeatedly calls `parse_case_clause` to parse one clause at a time, accumulating them until `parse_case_clause` fails.\nReturns `{:ok, %Ast.CaseExpression{}, remaining_tokens}` (where remaining tokens are after the last clause) or `{:error, reason}` if the very first clause fails.","deps":["parse_case_clause","parse_case_clauses"]},{"code":"def parse_case_expression(tokens) do\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"case\"),\n         {:ok, expr, tokens} <- parse_expression(tokens),\n         # ⭐ new\n         tokens = skip_newlines(tokens),\n         {:ok, _, tokens} <- expect_keyword(tokens, \"of\") do\n      parse_case_clauses(tokens, expr, [])\n    else\n      other -> other\n    end\n  end","name":"parse_case_expression","description":"Parses a case expression of the form `case expression of clauses`.\nIt expects the keywords \"case\" and \"of\", parses the expression being matched, skips newlines, and then calls `parse_case_clauses` to parse the individual clauses.\nReturns `{:ok, %Ast.CaseExpression{}, remaining_tokens}` or an error tuple.","deps":["expect_keyword","parse_expression","skip_newlines","parse_case_clauses"]},{"code":"# ------------------------------------------------------------\n  # 3. comparison (== != < <= > >=)\n  # ------------------------------------------------------------\n  defp parse_comparison_expression(tokens) do\n    tokens = skip_newlines(tokens)\n\n    with {:ok, left, tokens} <- parse_additive_expression(tokens) do\n      tokens = skip_newlines(tokens)\n\n      case tokens do\n        [%Token{type: :operator, value: op} | rest]\n        when op in [\"==\", \"!=\", \"<\", \"<=\", \">\", \">=\"] ->\n          rest = skip_newlines(rest)\n\n          with {:ok, right, rest} <- parse_comparison_expression(rest) do\n            {:ok, %Ast.BinaryOp{op: op, left: left, right: right}, rest}\n          end\n\n        _ ->\n          {:ok, left, tokens}\n      end\n    end\n  end","name":"parse_comparison_expression","description":"Parses expressions involving comparison operators \"==\", \"!=\", \"<\", \"<=\", \">\", \">=\".\nIt parses the left side using `parse_additive_expression` (higher precedence) and then, if a comparison operator is found, recursively parses the right side using itself. Comparison operators are right-associative.\nReturns `{:ok, expression_ast, remaining_tokens}`.","deps":["skip_newlines","parse_additive_expression","parse_comparison_expression"]},{"code":"defp parse_cons_pattern(tokens) do\n    with {:ok, head, tokens} <- parse_simple_pattern(tokens),\n         # the \":\" itself\n         {:ok, _, tokens} <- expect_colon(tokens),\n         {:ok, tail, tokens} <- parse_pattern(tokens) do\n      {:ok,\n       %Ast.FunctionCall{\n         function: %Ast.Identifier{name: \":\"},\n         arguments: [head, tail]\n       }, tokens}\n    else\n      _ -> {:error, \"Expected cons pattern\"}\n    end\n  end","name":"parse_cons_pattern","description":"Parses a cons pattern for lists, of the form `Head : Tail`.\nIt parses a simple pattern for the head, expects the \":\" operator, and parses a general pattern for the tail.\nReturns `{:ok, %Ast.FunctionCall{} (representing the cons operator), remaining_tokens}` or an error tuple.","deps":["parse_simple_pattern","expect_colon","parse_pattern"]},{"code":"defp parse_constructor_pattern(tokens) do\n    with {:ok, constructor, tokens} <- parse_identifier(tokens),\n         {:ok, args, tokens} <- parse_many(&parse_pattern/1, tokens) do\n      if args == [] do\n        {:ok, %Ast.Identifier{name: constructor.name}, tokens}\n      else\n        {:ok,\n         %Ast.FunctionCall{\n           # <- wrap\n           function: %Ast.Identifier{name: constructor.name},\n           arguments: args\n         }, tokens}\n      end\n    else\n      {:error, _} -> {:error, \"Expected constructor pattern\"}\n    end\n  end","name":"parse_constructor_pattern","description":"Parses a constructor pattern, which is an identifier possibly followed by one or more patterns as arguments, e.g., `Just value` or `Nil`.\nIt parses an identifier and then uses `parse_many` to collect any following patterns as arguments.\nReturns `{:ok, pattern_ast (either %Ast.Identifier{} or %Ast.FunctionCall{}), remaining_tokens}` or an error tuple.","deps":["parse_identifier","parse_many","parse_pattern"]},{"code":"defp parse_data_constructor(tokens) do\n    with {:ok, constructor_name, tokens} <- parse_identifier(tokens),\n         # ⬇️  collect atomic types, not full applications\n         {:ok, fields, tokens} <- parse_many(&parse_type_atom/1, tokens) do\n      {:ok,\n       %Ast.DataConstructor{\n         name: constructor_name.name,\n         fields: fields\n       }, tokens}\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end","name":"parse_data_constructor","description":"Parses a single data constructor, which consists of a name followed by zero or more fields (type atoms).\nIt parses an identifier for the constructor name and then uses `parse_many` to collect any following type atoms as fields.\nReturns `{:ok, %Ast.DataConstructor{}, remaining_tokens}` or an error tuple.","deps":["parse_identifier","parse_many","parse_type_atom"]},{"code":"defp parse_data_constructors(tokens) do\n    parse_separated(&parse_data_constructor/1, &expect_operator(&1, \"|\"), tokens)\n  end","name":"parse_data_constructors","description":"Parses the list of data constructors in a data type declaration, separated by \"|\".\nIt uses `parse_separated` with `parse_data_constructor` as the item parser and `expect_operator` for \"|\".\nReturns `{:ok, list_of_constructors, remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_data_constructor","expect_operator"]},{"code":"# Data type declaration\n  defp parse_data_declaration(tokens) do\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"data\"),\n         {:ok, type_name, tokens} <- parse_identifier(tokens),\n         {:ok, type_vars, tokens} <- parse_many(&parse_identifier/1, tokens),\n         # <ΓöÇΓöÇ here\n         tokens = skip_newlines(tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"=\"),\n         # <ΓöÇΓöÇ and here\n         tokens = skip_newlines(tokens),\n         {:ok, constructors, tokens} <- parse_data_constructors(tokens) do\n      {:ok,\n       %Ast.DataType{\n         name: type_name.name,\n         type_vars: Enum.map(type_vars, fn var -> var.name end),\n         constructors: constructors\n       }, tokens}\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end","name":"parse_data_declaration","description":"Parses a data type declaration of the form `data TypeName TypeVar1 TypeVar2 = Constructor1 | Constructor2 ...`.\nIt expects the \"data\" keyword, parses the type name, parses zero or more type variables, expects \"=\", skips newlines, and parses the list of constructors separated by \"|\".\nReturns `{:ok, %Ast.DataType{}, remaining_tokens}` or an error tuple.","deps":["expect_keyword","parse_identifier","parse_many","skip_newlines","expect_operator","parse_data_constructors"]},{"code":"def parse_declaration(tokens) do\n    # try function+signature combo first\n    case parse_function_with_type_signature(tokens) do\n      {:ok, v, rest} ->\n        {:ok, v, rest}\n\n      {:error, _} ->\n        case parse_type_signature(tokens) do\n          {:ok, ts, rest} ->\n            {:ok, ts, rest}\n\n          {:error, _} ->\n            parse_any(\n              [\n                &parse_module/1,\n                &parse_import/1,\n                &parse_foreign_import_simple/1,\n                &parse_foreign_import/1,\n                &parse_data_declaration/1,\n                &parse_type_alias/1,\n                &parse_type_class/1,\n                &parse_type_class_instance/1,\n                &parse_function_declaration/1\n              ],\n              tokens\n            )\n        end\n    end\n  end","name":"parse_declaration","description":"Attempts to parse a single top-level declaration.\nIt tries parsers in a specific order: function with type signature, then type signature alone, then any of the other declaration types (module, import, data, type alias, type class, instance, function).\nUses `parse_any` to try multiple parsers.\nReturns `{:ok, ast_node, remaining_tokens}` or `{:error, reason}` if no declaration parser succeeds.","deps":["parse_function_with_type_signature","parse_type_signature","parse_any","parse_module","parse_import","parse_foreign_import_simple","parse_foreign_import","parse_data_declaration","parse_type_alias","parse_type_class","parse_type_class_instance","parse_function_declaration"]},{"code":"def parse_declarations(tokens), do: parse_declarations(tokens, [])\n  def parse_declarations([], acc), do: {:ok, Enum.reverse(acc), []}\n\n  def parse_declarations(tokens, acc) do\n    tokens = skip_newlines(tokens)\n\n    case parse_declaration(tokens) do\n      {:ok, decl, rest} -> parse_declarations(rest, [decl | acc])\n      {:error, _} when acc != [] -> {:ok, Enum.reverse(acc), tokens}\n      other -> other\n    end\n  end","name":"parse_declarations","description":"Parses a sequence of top-level declarations (like functions, data types, imports) from the token stream.\nIt works recursively, attempting to parse a single declaration, accumulating the results, and continuing with the rest of the tokens.\nNewlines are skipped before attempting to parse each declaration.\nReturns `{:ok, list_of_declarations, remaining_tokens}` or `{:error, reason}` if the first declaration fails.","deps":["parse_declarations","skip_newlines","parse_declaration"]},{"code":"defp parse_do_block(tokens) do\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"do\"),\n         {:ok, expressions, tokens} <- parse_many(&parse_do_expression/1, tokens),\n         remaining = skip_until_end(tokens) do\n      {:ok, %Ast.DoBlock{expressions: expressions}, remaining}\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end","name":"parse_do_block","description":"Parses a do-block expression of the form `do expressions end`.\nIt expects the \"do\" keyword, parses one or more expressions within the block using `parse_many` and `parse_do_expression`, and then skips tokens until (and including) the \"end\" keyword using `skip_until_end`.\nReturns `{:ok, %Ast.DoBlock{}, remaining_tokens_after_end}` or an error tuple.","deps":["expect_keyword","parse_many","parse_do_expression","skip_until_end"]},{"code":"defp parse_do_expression(tokens) do\n    parse_any(\n      [\n        fn tokens ->\n          with {:ok, _, tokens} <- expect_keyword(tokens, \"let\"),\n               {:ok, name, tokens} <- parse_identifier(tokens),\n               {:ok, _, tokens} <- expect_operator(tokens, \"=\"),\n               {:ok, value, tokens} <- parse_expression(tokens) do\n            {:ok, {:let, name.name, value}, tokens}\n          else\n            {:error, _} -> {:error, \"Expected let binding in do block\"}\n          end\n        end,\n        fn tokens ->\n          with {:ok, expr, tokens} <- parse_expression(tokens),\n               {:ok, _, tokens} <- expect_operator(tokens, \"<-\"),\n               {:ok, value, tokens} <- parse_expression(tokens) do\n            {:ok, {:bind, expr, value}, tokens}\n          else\n            {:error, _} -> {:error, \"Expected bind expression in do block\"}\n          end\n        end,\n        fn tokens ->\n          with {:ok, expr, tokens} <- parse_expression(tokens) do\n            {:ok, {:expr, expr}, tokens}\n          else\n            {:error, _} -> {:error, \"Expected expression in do block\"}\n          end\n        end\n      ],\n      tokens\n    )\n  end","name":"parse_do_expression","description":"Parses a single expression within a do-block.\nAn expression in a do-block can be a simple expression, a let binding (`let name = value`), or a bind operation (`pattern <- value`).\nUses `parse_any` to try these different forms.\nReturns `{:ok, representation_tuple, remaining_tokens}` or an error tuple if none succeed.","deps":["parse_any","expect_keyword","parse_identifier","expect_operator","parse_expression"]},{"code":"defp parse_dollar_expression(tokens) do\n    # first parse *anything* tighter than '$'\n    with {:ok, left, tokens} <- parse_logical_expression(tokens) do\n      tokens = skip_newlines(tokens)\n\n      case tokens do\n        [%Token{type: :operator, value: \"$\"} | rest] ->\n          rest = skip_newlines(rest)\n\n          # right-associative: parse the *whole* rhs with the same rule\n          with {:ok, right, rest} <- parse_dollar_expression(rest) do\n            {:ok, %Ast.FunctionCall{function: left, arguments: [right]}, rest}\n          end\n\n        _ ->\n          {:ok, left, tokens}\n      end\n    end\n  end","name":"parse_dollar_expression","description":"Parses expressions involving the right-associative \"$\" operator (function application).\nIt parses the left side using `parse_logical_expression` (which has higher precedence) and then, if \"$\" is found, recursively parses the right side using itself.\nReturns `{:ok, expression_ast, remaining_tokens}`.","deps":["parse_logical_expression","skip_newlines","parse_dollar_expression"]},{"code":"# Expression parsing\n  def parse_expression(tokens) do\n    parse_binary_expression(tokens)\n  end","name":"parse_expression","description":"The main entry point for parsing general expressions.\nCurrently, it simply dispatches to `parse_binary_expression`, which handles operator precedence and other top-level expression forms.\nReturns `{:ok, expression_ast, remaining_tokens}` or an error tuple.","deps":["parse_binary_expression"]},{"code":"# forall a b.  ty\n  defp parse_forall_type([%Token{value: \"forall\"} | rest]) do\n    with {:ok, vars, rest} <- parse_many(&parse_identifier/1, rest),\n         {:ok, _, rest} <- expect_operator(rest, \".\"),\n         {:ok, ty, rest} <- parse_type(rest) do\n      {:ok, %Ast.ForAllType{vars: Enum.map(vars, & &1.name), type: ty}, rest}\n    end\n  end","name":"parse_forall_type","description":"Parses a \"forall\" type quantification of the form `forall a b. Type`.\nIt expects the \"forall\" keyword, parses one or more type variables (identifiers), expects \".\", and then parses the rest of the type expression.\nReturns `{:ok, %Ast.ForAllType{}, remaining_tokens}`.","deps":["parse_many","parse_identifier","expect_operator","parse_type"]},{"code":"defp parse_foreign_import(tokens) do\n    tokens = drop_newlines(tokens)\n\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"foreign\"),\n         {:ok, _, tokens} <- expect_keyword(tokens, \"import\"),\n         # ⬇︎ target language is an identifier (keep it if you ever need it)\n         {:ok, _lang, tokens} <- parse_identifier(tokens),\n         {:ok, mod, tokens} <- parse_string_literal(tokens),\n         {:ok, fun, tokens} <- parse_string_literal(tokens),\n         {:ok, al, tokens} <- parse_identifier(tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"::\"),\n         {:ok, type, tokens} <- parse_type(tokens) do\n      {:ok,\n       %Ast.ForeignImport{\n         module: mod,\n         function: fun,\n         alias: al.name,\n         type_signature: %Ast.TypeSignature{\n           name: al.name,\n           type_vars: [],\n           constraints: [],\n           type: type\n         }\n       }, tokens}\n    else\n      other -> other\n    end\n  end","name":"parse_foreign_import","description":"Parses a detailed foreign import declaration of the form `foreign import lang module_string function_string alias :: Type`.\nIt expects the keywords \"foreign\" and \"import\", parses a language identifier, two string literals for module and function names, an identifier for the local alias, expects \"::\", and parses the foreign type signature.\nReturns `{:ok, %Ast.ForeignImport{}, remaining_tokens}` or an error tuple.","deps":["drop_newlines","expect_keyword","parse_identifier","parse_string_literal","expect_operator","parse_type"]},{"code":"defp parse_foreign_import_simple(tokens) do\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"foreign\"),\n         {:ok, _, tokens} <- expect_keyword(tokens, \"import\"),\n         {:ok, name, tokens} <- parse_identifier(tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"::\"),\n         {:ok, type, tokens} <- parse_type(tokens) do\n      {:ok,\n       %Ast.ForeignImport{\n         # not specified\n         module: nil,\n         # not specified\n         function: nil,\n         # the identifier itself\n         alias: name.name,\n         type_signature: %Ast.TypeSignature{\n           name: name.name,\n           type_vars: [],\n           constraints: [],\n           type: type\n         }\n       }, drop_newlines(tokens)}\n    else\n      _ -> {:error, \"plain foreign import parse failed\"}\n    end\n  end","name":"parse_foreign_import_simple","description":"Parses a simple foreign import declaration of the form `foreign import name :: Type`.\nIt expects the keywords \"foreign\" and \"import\", parses an identifier for the local name, expects \"::\", and parses the foreign type signature.\nReturns `{:ok, %Ast.ForeignImport{}, remaining_tokens}` or an error tuple.","deps":["expect_keyword","parse_identifier","expect_operator","parse_type","drop_newlines"]},{"code":"# ------------------------------------------------------------\n  #  Function declaration (no type signature)                   \n  # ------------------------------------------------------------\n  defp parse_function_declaration(tokens) do\n    with {:ok, name, tokens} <- parse_identifier(tokens),\n         {:ok, parameters, tokens} <- parse_function_parameters(tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"=\"),\n         {:ok, body, tokens} <- parse_expression(tokens) do\n      {:ok,\n       %Ast.FunctionDeclaration{\n         name: name.name,\n         # ← keep full pattern nodes\n         parameters: parameters,\n         body: body,\n         type_signature: nil\n       }, tokens}\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end","name":"parse_function_declaration","description":"Parses a function declaration without a preceding type signature, of the form `name parameters = body`.\nIt parses the function name (identifier), the parameters (simple patterns), expects \"=\", and parses the function body (expression).\nReturns `{:ok, %Ast.FunctionDeclaration{}, remaining_tokens}` or an error tuple.","deps":["parse_identifier","parse_function_parameters","expect_operator","parse_expression"]},{"code":"defp parse_function_parameters(tokens), do: parse_many(&parse_simple_pattern/1, tokens)","name":"parse_function_parameters","description":"Parses the parameters part of a function declaration or lambda, which is a sequence of zero or more simple patterns.\nIt uses `parse_many` to collect simple patterns.\nReturns `{:ok, list_of_patterns, remaining_tokens}`.","deps":["parse_many","parse_simple_pattern"]},{"code":"defp parse_function_type(tokens) do\n    with {:ok, left, tokens} <- parse_type_term(tokens) do\n      case tokens do\n        [%Token{type: :operator, value: \"->\"} | rest] ->\n          with {:ok, right, rest} <- parse_function_type(rest) do\n            {:ok, %Ast.BinaryOp{op: \"->\", left: left, right: right}, rest}\n          end\n\n        _ ->\n          {:ok, left, tokens}\n      end\n    end\n  end","name":"parse_function_type","description":"Parses a function type expression, which is a sequence of type terms separated by \"->\", e.g., `A -> B -> C`.\nIt parses the first term using `parse_type_term` and then recursively parses the rest if \"->\" is encountered. Function types are right-associative.\nReturns `{:ok, type_ast, remaining_tokens}`.","deps":["parse_type_term","parse_function_type"]},{"code":"# Parse a function declaration with its type signature\n  defp parse_function_with_type_signature(tokens) do\n    tokens = drop_newlines(tokens)\n\n    case tokens do\n      [%Token{type: :identifier, value: name} | rest1] ->\n        with {:ok, _, rest2} <- expect_operator(rest1, \"::\"),\n             {type_tokens, rest3} <- split_type_and_rest(rest2, name),\n             {:ok, type_ast, []} <- parse_type(strip_newlines(type_tokens)),\n             {:ok, fun_ast, final} <- parse_function_declaration(rest3),\n             true <- fun_ast.name == name do\n          {:ok,\n           %Ast.FunctionDeclaration{\n             name: fun_ast.name,\n             parameters: fun_ast.parameters,\n             body: fun_ast.body,\n             type_signature: %Ast.TypeSignature{\n               name: name,\n               type_vars: [],\n               constraints: [],\n               type: type_ast\n             }\n           }, final}\n        else\n          _ -> {:error, \"function-with-signature parse failed\"}\n        end\n\n      _ ->\n        {:error, \"Expected identifier at start of type signature\"}\n    end\n  end","name":"parse_function_with_type_signature","description":"Parses a function declaration that includes a preceding type signature, e.g., `name :: Type name parameters = body`.\nIt expects an identifier, then \"::\", splits the tokens to isolate the type signature part, parses the type, then parses the function declaration, and verifies the names match.\nReturns `{:ok, %Ast.FunctionDeclaration{} with type_signature, remaining_tokens}` or an error tuple.","deps":["drop_newlines","expect_operator","split_type_and_rest","parse_type","strip_newlines","parse_function_declaration"]},{"code":"defp parse_generator(tokens) do\n    with {:ok, pattern, tokens} <- parse_pattern(tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"<-\"),\n         {:ok, expression, tokens} <- parse_expression(tokens) do\n      {:ok, %Ast.Generator{pattern: pattern, expression: expression}, tokens}\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end","name":"parse_generator","description":"Parses a single generator within a list comprehension, of the form `pattern <- expression`.\nIt parses a pattern, expects \"<-\", and parses the source expression.\nReturns `{:ok, %Ast.Generator{}, remaining_tokens}` or an error tuple.","deps":["parse_pattern","expect_operator","parse_expression"]},{"code":"defp parse_if_expression(tokens) do\n    tokens = skip_newlines(tokens)\n\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"if\"),\n         {:ok, condition, tokens} <- parse_expression(tokens),\n         {:ok, _, tokens} <- expect_keyword(tokens, \"then\"),\n         {:ok, then_branch, tokens} <- parse_expression(tokens),\n         {:ok, _, tokens} <- expect_keyword(tokens, \"else\"),\n         {:ok, else_branch, tokens} <- parse_expression(tokens) do\n      {:ok,\n       %Ast.IfExpression{\n         condition: condition,\n         then_branch: then_branch,\n         else_branch: else_branch\n       }, tokens}\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end","name":"parse_if_expression","description":"Parses an if expression of the form `if condition then then_branch else else_branch`.\nIt expects the keywords \"if\", \"then\", and \"else\", parsing the condition, then branch, and else branch expressions in between.\nReturns `{:ok, %Ast.IfExpression{}, remaining_tokens}` or an error tuple.","deps":["skip_newlines","expect_keyword","parse_expression"]},{"code":"defp parse_import(tokens) do\n    tokens = drop_newlines(tokens)\n\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"import\"),\n         {:ok, mod, tokens} <- parse_qualified_identifier(tokens),\n         {alias, tokens} <- parse_import_alias(tokens),\n         {:ok, items, hiding?, tokens} <- parse_import_selectors(tokens) do\n      {:ok,\n       %Ast.ImportDeclaration{\n         module: mod,\n         alias: alias,\n         items: items,\n         hiding?: hiding?\n       }, drop_newlines(tokens)}\n    end\n  end","name":"parse_import","description":"Parses an import declaration of the form `import Module.Name [as Alias] [( Items ) | hiding ( Items )]`.\nIt expects the \"import\" keyword, parses the module name, optionally parses an alias, and then parses the import selectors (items to import or hide).\nReturns `{:ok, %Ast.ImportDeclaration{}, remaining_tokens}`.","deps":["drop_newlines","expect_keyword","parse_qualified_identifier","parse_import_alias","parse_import_selectors"]},{"code":"# Lambda expression parsing\n  defp parse_lambda(tokens) do\n    with {:ok, _, tokens} <- expect_operator(tokens, \"\\\\\"),\n         {:ok, parameters, tokens} <- parse_function_parameters(tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"->\"),\n         {:ok, body, tokens} <- parse_expression(tokens) do\n      {:ok, %Ast.Lambda{parameters: parameters, body: body}, tokens}\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end","name":"parse_lambda","description":"Parses a lambda expression of the form `\\parameters -> body`.\nIt expects the \"\\\" operator, parses the parameters using `parse_function_parameters`, expects the \"->\" operator, and parses the body expression.\nReturns `{:ok, %Ast.Lambda{}, remaining_tokens}` or an error tuple.","deps":["expect_operator","parse_function_parameters","parse_expression"]},{"code":"# ------------------------------------------------------------\n  #  Let-expression  (layout-aware)\n  # ------------------------------------------------------------\n  def parse_let_expression(tokens) do\n    tokens = skip_newlines(tokens)\n\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"let\"),\n         # gap A\n         tokens = skip_newlines(tokens),\n         {:ok, bindings, tokens} <- parse_many(&parse_binding/1, tokens),\n         # gap B\n         tokens = skip_newlines(tokens),\n         {:ok, _, tokens} <- expect_keyword(tokens, \"in\"),\n         # gap C\n         tokens = skip_newlines(tokens),\n         {:ok, body, tokens} <- parse_expression(tokens) do\n      {:ok, %Ast.LetBinding{bindings: bindings, body: body}, tokens}\n    else\n      {:error, reason} -> {:error, reason}\n    end\n  end","name":"parse_let_expression","description":"Parses a let expression of the form `let bindings in body`.\nIt expects the \"let\" keyword, skips newlines, parses one or more bindings using `parse_many` and `parse_binding`, expects the \"in\" keyword, skips newlines, and parses the body expression.\nReturns `{:ok, %Ast.LetBinding{}, remaining_tokens}` or an error tuple.","deps":["skip_newlines","expect_keyword","parse_many","parse_binding","parse_expression"]},{"code":"defp parse_list_comprehension(tokens) do\n    case tokens do\n      [%Token{type: :delimiter, value: \"[\"} | rest] ->\n        with {:ok, expression, rest} <- parse_expression(rest),\n             {:ok, _, rest} <- expect_operator(rest, \"|\"),\n             {:ok, generators, rest} <-\n               parse_separated(&parse_generator/1, &expect_delimiter(&1, \",\"), rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \"]\") do\n          {:ok,\n           %Ast.ListComprehension{expression: expression, generators: generators, guards: []},\n           rest}\n        end\n\n      _ ->\n        {:error, \"Expected list comprehension\"}\n    end\n  end","name":"parse_list_comprehension","description":"Parses a list comprehension expression of the form `[ expression | generator1, generator2, ... ]`.\nIt expects an opening bracket, parses the result expression, expects \"|\", parses a comma-separated list of generators using `parse_separated` and `parse_generator`, and expects a closing bracket. Guards are currently not parsed.\nReturns `{:ok, %Ast.ListComprehension{}, remaining_tokens}` or an error tuple.","deps":["parse_expression","expect_operator","parse_separated","parse_generator","expect_delimiter"]},{"code":"defp parse_list_literal(tokens) do\n    case tokens do\n      [%Token{type: :delimiter, value: \"[\"} | rest] ->\n        with {:ok, elements, rest} <-\n               parse_separated(&parse_expression/1, &expect_delimiter(&1, \",\"), rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \"]\") do\n          {:ok, %Ast.List{elements: elements}, rest}\n        end\n\n      _ ->\n        {:error, \"Expected list literal\"}\n    end\n  end","name":"parse_list_literal","description":"Parses a list literal expression of the form `[element1, element2, ...]`.\nIt expects an opening bracket, parses a comma-separated list of expressions using `parse_separated` and `parse_expression`, and expects a closing bracket.\nReturns `{:ok, %Ast.List{}, remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_expression","expect_delimiter"]},{"code":"defp parse_list_pattern(tokens) do\n    case tokens do\n      [%Token{type: :delimiter, value: \"[\"} | rest] ->\n        with {:ok, elements, rest} <-\n               parse_separated(&parse_pattern/1, &expect_delimiter(&1, \",\"), rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \"]\") do\n          {:ok, %Ast.List{elements: elements}, rest}\n        end\n\n      [%Token{type: :delimiter, value: \"[\"} | rest] ->\n        {:ok, %Ast.List{elements: []}, rest}\n\n      _ ->\n        {:error, \"Expected list pattern\"}\n    end\n  end","name":"parse_list_pattern","description":"Parses a list pattern of the form `[pattern1, pattern2, ...]` or `[]`.\nIt expects an opening bracket, parses an optional comma-separated list of patterns, and expects a closing bracket.\nHandles the empty list case specifically.\nReturns `{:ok, %Ast.List{}, remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_pattern","expect_delimiter"]},{"code":"defp parse_list_type(tokens) do\n    case tokens do\n      [%Token{type: :delimiter, value: \"[\"} | rest] ->\n        with {:ok, element_type, rest} <- parse_type(rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \"]\") do\n          {:ok, %Ast.FunctionCall{function: \"[]\", arguments: [element_type]}, rest}\n        end\n\n      _ ->\n        {:error, \"Expected list type\"}\n    end\n  end","name":"parse_list_type","description":"Parses a list type expression of the form `[ElementType]`.\nIt expects an opening bracket, parses the element type using `parse_type`, and expects a closing bracket.\nReturns `{:ok, %Ast.FunctionCall{} (representing the list type constructor), remaining_tokens}` or an error tuple.","deps":["parse_type","expect_delimiter"]},{"code":"# ------------------------------------------------------------\n  # 2. logical  (&&  ||)  – lowest precedence\n  # ------------------------------------------------------------\n  defp parse_logical_expression(tokens) do\n    with {:ok, left, tokens} <- parse_comparison_expression(tokens) do\n      case tokens do\n        [%Token{type: :operator, value: op} | rest] when op in [\"&&\", \"||\"] ->\n          with {:ok, right, rest} <- parse_logical_expression(rest) do\n            {:ok, %Ast.BinaryOp{op: op, left: left, right: right}, rest}\n          end\n\n        _ ->\n          {:ok, left, tokens}\n      end\n    end\n  end","name":"parse_logical_expression","description":"Parses expressions involving logical operators \"&&\" and \"||\".\nIt parses the left side using `parse_comparison_expression` (higher precedence) and then, if a logical operator is found, recursively parses the right side using itself. Logical operators are right-associative.\nReturns `{:ok, expression_ast, remaining_tokens}`.","deps":["parse_comparison_expression","parse_logical_expression"]},{"code":"def parse_many(parser, tokens) do\n    parse_many(parser, tokens, [])\n  end\n\n  def parse_many(parser, tokens, acc) do\n    case parser.(tokens) do\n      {:ok, result, remaining} ->\n        parse_many(parser, remaining, [result | acc])\n\n      {:error, _} ->\n        {:ok, Enum.reverse(acc), tokens}\n    end\n  end","name":"parse_many","description":"Parses zero or more occurrences of an item using a given parser.\nIt repeatedly calls the provided `parser` function on the remaining tokens, accumulating the results until the parser fails.\nReturns `{:ok, list_of_results, remaining_tokens}` (where remaining tokens are the ones where the parser first failed).","deps":["parse_many"]},{"code":"def parse_module(tokens) do\n    tokens = drop_newlines(tokens)\n\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"module\"),\n         {:ok, module_name, tokens} <- parse_qualified_identifier(tokens),\n         {:ok, _, tokens} <- expect_keyword(tokens, \"where\") do\n      {:ok, %Ast.Module{name: module_name}, tokens}\n    else\n      other -> other\n    end\n  end","name":"parse_module","description":"Parses a module declaration of the form `module Module.Name where ...`.\nIt expects the keywords \"module\" and \"where\" and parses a qualified identifier for the module name in between.\nReturns `{:ok, %Ast.Module{}, remaining_tokens}` or an error tuple if the expected structure is not found.","deps":["drop_newlines","expect_keyword","parse_qualified_identifier"]},{"code":"# 5. multiplicative (* /)\n  # ------------------------------------------------------------\n  defp parse_multiplicative_expression(tokens) do\n    # <- was parse_comparison_expression/1\n    with {:ok, left, tokens} <- parse_application(tokens) do\n      case tokens do\n        [%Token{type: :operator, value: op} | rest] when op in [\"*\", \"/\"] ->\n          with {:ok, right, rest} <- parse_multiplicative_expression(rest) do\n            {:ok, %Ast.BinaryOp{op: op, left: left, right: right}, rest}\n          end\n\n        [\n          %Token{type: :operator, value: \"`\"},\n          %Token{type: :identifier, value: fun},\n          %Token{type: :operator, value: \"`\"} | rest\n        ] ->\n          with {:ok, right, rest} <- parse_multiplicative_expression(rest) do\n            {:ok,\n             %Ast.FunctionCall{\n               function: %Ast.Identifier{name: fun},\n               arguments: [left, right]\n             }, rest}\n          end\n\n        _ ->\n          {:ok, left, tokens}\n      end\n    end\n  end","name":"parse_multiplicative_expression","description":"Parses expressions involving multiplicative operators \"*\" and \"/\".\nIt parses the left side using `parse_application` (higher precedence) and then, if a multiplicative operator is found, recursively parses the right side using itself. It also handles backtick-quoted operators (infix function calls). Multiplicative operators are right-associative.\nReturns `{:ok, expression_ast, remaining_tokens}`.","deps":["parse_application","parse_multiplicative_expression"]},{"code":"# Pattern parsing for other contexts like case clauses\n  def parse_pattern(tokens) do\n    parse_any(\n      [\n        &parse_record_pattern/1,\n        &parse_wildcard_pattern/1,\n        &parse_cons_pattern/1,\n        &parse_constructor_pattern/1,\n        &parse_tuple_pattern/1,\n        &parse_list_pattern/1,\n        &parse_literal/1,\n        &parse_identifier/1,\n        fn tokens ->\n          case tokens do\n            [%Token{type: :delimiter, value: \"(\"} | rest] ->\n              with {:ok, pattern, rest} <- parse_pattern(rest),\n                   {:ok, _, rest} <- expect_delimiter(rest, \")\") do\n                {:ok, pattern, rest}\n              end\n\n            _ ->\n              {:error, \"Expected parenthesized pattern\"}\n          end\n        end\n      ],\n      tokens\n    )\n  end","name":"parse_pattern","description":"Parses a general pattern, used in case expressions, let bindings, etc.\nIncludes record patterns, wildcard patterns, cons patterns, constructor patterns, tuple patterns, list patterns, literals, identifiers, and parenthesized patterns.\nUses `parse_any` to try multiple pattern parsers.\nReturns `{:ok, pattern_ast, remaining_tokens}` or an error tuple if none succeed.","deps":["parse_any","parse_record_pattern","parse_wildcard_pattern","parse_cons_pattern","parse_constructor_pattern","parse_tuple_pattern","parse_list_pattern","parse_literal","parse_identifier","parse_pattern","expect_delimiter"]},{"code":"defp parse_record_field(tokens) do\n    with {:ok, label, tokens} <- parse_label(tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"::\"),\n         tokens = skip_newlines(tokens),\n         {:ok, t, tokens} <- parse_type(tokens) do\n      {:ok, {label.name, t}, tokens}\n    end\n  end","name":"parse_record_field","description":"Parses a single field within a record type expression, of the form `label :: Type`.\nIt parses a label, expects \"::\", skips newlines, and parses the field's type.\nReturns `{:ok, {label_name, type_ast}, remaining_tokens}`.","deps":["parse_label","expect_operator","skip_newlines","parse_type"]},{"code":"defp parse_record_field_expr(tokens) do\n    with {:ok, label, tokens} <- parse_identifier(tokens),\n         # uses the new ':'\n         {:ok, _, tokens} <- expect_delimiter(tokens, \":\"),\n         tokens = skip_newlines(tokens),\n         {:ok, expr, tokens} <- parse_expression(tokens) do\n      {:ok, {label.name, expr}, tokens}\n    end\n  end","name":"parse_record_field_expr","description":"Parses a single field within a record literal expression, of the form `label : expression`.\nIt parses an identifier for the label, expects \":\", skips newlines, and parses the field's value expression.\nReturns `{:ok, {label_name, expression_ast}, remaining_tokens}`.","deps":["parse_identifier","expect_delimiter","skip_newlines","parse_expression"]},{"code":"defp parse_record_field_pattern(tokens) do\n    with {:ok, lbl, tokens} <- IO.inspect(parse_label(tokens)) do\n      cond do\n        # ──────────────── `:` delimiter ────────────────\n        match?({:ok, _, _}, expect_delimiter(tokens, \":\")) ->\n          {:ok, _, tokens} = expect_delimiter(tokens, \":\")\n\n          with {:ok, pat, tokens} <- parse_pattern(tokens) do\n            {:ok, {lbl.name, pat}, tokens}\n          end\n\n        # ──────────────── `=` operator ────────────────\n        match?({:ok, _, _}, expect_operator(tokens, \"=\")) ->\n          {:ok, _, tokens} = expect_operator(tokens, \"=\")\n\n          with {:ok, pat, tokens} <- parse_pattern(tokens) do\n            {:ok, {lbl.name, pat}, tokens}\n          end\n\n        # ─────────── shorthand  { head } ───────────────\n        true ->\n          {:ok, {lbl.name, %Ast.Identifier{name: lbl.name}}, tokens}\n      end\n    end\n  end","name":"parse_record_field_pattern","description":"Parses a single field within a record pattern.\nA field can be `label: pattern`, `label = pattern`, or just `label` (shorthand for `label: label`).\nIt first parses the label and then checks for `:` or `=` to determine the structure.\nReturns `{:ok, {label_name, pattern_ast}, remaining_tokens}`.","deps":["parse_label","expect_delimiter","parse_pattern","expect_operator"]},{"code":"── record literal  ─────────────────────────────────────────\n  defp parse_record_literal([%Token{type: :delimiter, value: \"{\"} | rest]) do\n    with {:ok, fields, rest} <-\n           parse_separated(&parse_record_field_expr/1, &expect_delimiter(&1, \",\"), rest),\n         {:ok, _, rest} <- expect_delimiter(rest, \"}\") do\n      {:ok, %Ast.RecordLiteral{fields: fields}, rest}\n    end\n  end\n\n  defp parse_record_literal(_), do: {:error, \"Expected record literal\"}","name":"parse_record_literal","description":"Parses a record literal expression of the form `{ field1: value1, field2: value2, ... }`.\nIt expects an opening brace, parses a comma-separated list of record fields using `parse_record_field_expr`, and expects a closing brace.\nReturns `{:ok, %Ast.RecordLiteral{}, remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_record_field_expr","expect_delimiter"]},{"code":"defp parse_record_pattern([%Token{type: :delimiter, value: \"{\"} | rest]) do\n    with {:ok, fields, rest} <-\n           parse_separated(&parse_record_field_pattern/1, &expect_delimiter(&1, \",\"), rest),\n         {:ok, _, rest} <- expect_delimiter(rest, \"}\") do\n      {:ok, %Ast.RecordPattern{fields: fields}, rest}\n    end\n  end\n\n  defp parse_record_pattern(_), do: {:error, \"Expected record pattern\"}","name":"parse_record_pattern","description":"Parses a record pattern of the form `{ field1: pattern1, field2, ... }`.\nIt expects an opening brace, parses a comma-separated list of record field patterns, and expects a closing brace.\nReturns `{:ok, %Ast.RecordPattern{}, remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_record_field_pattern","expect_delimiter"]},{"code":"# 2. Parser helpers\n  def parse_record_type([%Token{type: :delimiter, value: \"{\"} | rest]) do\n    with {:ok, fields, rest} <-\n           parse_separated(&parse_record_field/1, &expect_delimiter(&1, \",\"), rest),\n         {:ok, _, rest} <- expect_delimiter(rest, \"}\") do\n      {:ok, %Ast.RecordType{fields: fields}, rest}\n    end\n  end\n\n  def parse_record_type(_), do: {:error, \"Expected record type\"}","name":"parse_record_type","description":"Parses a record type expression of the form `{ field1 :: Type1, field2 :: Type2, ... }`.\nIt expects an opening brace, parses a comma-separated list of record fields, and expects a closing brace.\nReturns `{:ok, %Ast.RecordType{}, remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_record_field","expect_delimiter"]},{"code":"# ------------------------------------------------------------\n  #  Simple pattern (for parameters)\n  # ------------------------------------------------------------\n  defp parse_simple_pattern(tokens) do\n    parse_any(\n      [\n        &parse_literal/1,\n        &parse_identifier/1,\n        &parse_tuple_pattern/1,\n        &parse_list_pattern/1,\n        fn\n          [%Token{type: :delimiter, value: \"(\"} | rest] ->\n            with {:ok, pattern, rest} <- parse_pattern(rest),\n                 {:ok, _, rest} <- expect_delimiter(rest, \")\") do\n              {:ok, pattern, rest}\n            end\n\n          _ ->\n            {:error, \"Expected parenthesized pattern\"}\n        end\n      ],\n      tokens\n    )\n  end","name":"parse_simple_pattern","description":"Parses a \"simple\" pattern, which is a subset of full patterns allowed in function parameters or lambda arguments.\nSimple patterns include literals, identifiers, tuple patterns, list patterns, and parenthesized patterns.\nUses `parse_any` to try multiple simple pattern parsers.\nReturns `{:ok, pattern_ast, remaining_tokens}` or an error tuple if none succeed.","deps":["parse_any","parse_literal","parse_identifier","parse_tuple_pattern","parse_list_pattern","parse_pattern","expect_delimiter"]},{"code":"defp parse_term(tokens) do\n    parse_any(\n      [\n        &parse_record_literal/1,\n        &parse_literal/1,\n        &parse_list_literal/1,\n        &parse_list_comprehension/1,\n        &parse_tuple_literal/1,\n        &parse_qualified_identifier/1,\n        fn tokens ->\n          case tokens do\n            [%Token{type: :delimiter, value: \"(\"} | rest] ->\n              with {:ok, expr, rest} <- parse_expression(rest),\n                   {:ok, _, rest} <- expect_delimiter(rest, \")\") do\n                {:ok, expr, rest}\n              end\n\n            _ ->\n              {:error, \"Expected parenthesized expression\"}\n          end\n        end\n      ],\n      tokens\n    )\n  end","name":"parse_term","description":"Parses a basic term in an expression, which can be a record literal, literal, list literal, list comprehension, tuple literal, qualified identifier, or a parenthesized expression.\nUses `parse_any` to try multiple term parsers.\nReturns `{:ok, term_ast, remaining_tokens}` or an error tuple if none succeed.","deps":["parse_any","parse_record_literal","parse_literal","parse_list_literal","parse_list_comprehension","parse_tuple_literal","parse_qualified_identifier","parse_expression","expect_delimiter"]},{"code":"defp parse_tuple_literal(tokens) do\n    case tokens do\n      [%Token{type: :delimiter, value: \"(\"} | rest] ->\n        with {:ok, elements, rest} <-\n               parse_separated(&parse_expression/1, &expect_delimiter(&1, \",\"), rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \")\") do\n          if length(elements) == 1 do\n            # Single element in parentheses is just grouping, not a tuple\n            {:ok, List.first(elements), rest}\n          else\n            {:ok, %Ast.Tuple{elements: elements}, rest}\n          end\n        end\n\n      _ ->\n        {:error, \"Expected tuple literal\"}\n    end\n  end","name":"parse_tuple_literal","description":"Parses a tuple literal expression of the form `(element1, element2, ...)`.\nIt expects an opening parenthesis, parses a comma-separated list of expressions using `parse_separated` and `parse_expression`, and expects a closing parenthesis.\nHandles the case of a single element in parentheses as just grouping.\nReturns `{:ok, expression_ast (either %Ast.Tuple{} or the inner expression), remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_expression","expect_delimiter"]},{"code":"defp parse_tuple_pattern(tokens) do\n    case tokens do\n      [%Token{type: :delimiter, value: \"(\"} | rest] ->\n        with {:ok, elements, rest} <-\n               parse_separated(&parse_pattern/1, &expect_delimiter(&1, \",\"), rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \")\") do\n          {:ok, %Ast.Tuple{elements: elements}, rest}\n        end\n\n      _ ->\n        {:error, \"Expected tuple pattern\"}\n    end\n  end","name":"parse_tuple_pattern","description":"Parses a tuple pattern of the form `(pattern1, pattern2, ...)`.\nIt expects an opening parenthesis, parses a comma-separated list of patterns, and expects a closing parenthesis.\nReturns `{:ok, %Ast.Tuple{}, remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_pattern","expect_delimiter"]},{"code":"defp parse_tuple_type(tokens) do\n    case tokens do\n      [%Token{type: :delimiter, value: \"(\"} | rest] ->\n        with {:ok, elements, rest} <-\n               parse_separated(&parse_type/1, &expect_delimiter(&1, \",\"), rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \")\") do\n          if length(elements) == 1 do\n            # Parentheses used only for grouping → return the inner type\n            {:ok, List.first(elements), rest}\n          else\n            # Real tuple type\n            {:ok, %Ast.Tuple{elements: elements}, rest}\n          end\n        end\n\n      _ ->\n        {:error, \"Expected tuple type\"}\n    end\n  end","name":"parse_tuple_type","description":"Parses a tuple type expression of the form `(Type1, Type2, ...)`.\nIt expects an opening parenthesis, parses a comma-separated list of types, and expects a closing parenthesis.\nHandles the case of a single element in parentheses as just grouping.\nReturns `{:ok, type_ast (either %Ast.Tuple{} or the inner type), remaining_tokens}` or an error tuple.","deps":["parse_separated","parse_type","expect_delimiter"]},{"code":"# Type parsing\n  defp parse_type([%Token{type: :identifier, value: \"forall\"} | _] = toks),\n    do: parse_forall_type(toks)\n\n  defp parse_type(toks), do: parse_function_type(toks)","name":"parse_type","description":"Entry point for parsing type expressions.\nIt dispatches to `parse_forall_type` if the type starts with \"forall\", otherwise it dispatches to `parse_function_type`.\nReturns `{:ok, type_ast, remaining_tokens}` or an error tuple from the dispatched parser.","deps":["parse_forall_type","parse_function_type"]},{"code":"defp parse_type_alias(tokens) do\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"type\"),\n         {:ok, name, tokens} <- parse_identifier(tokens),\n         {:ok, vars, tokens} <- parse_many(&parse_identifier/1, tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"=\"),\n         tokens = skip_newlines(tokens),\n         {:ok, aliased, tokens} <- parse_type(tokens) do\n      {:ok,\n       %Ast.TypeAlias{\n         name: name.name,\n         type_vars: Enum.map(vars, & &1.name),\n         type: aliased\n       }, tokens}\n    else\n      other -> other\n    end\n  end","name":"parse_type_alias","description":"Parses a type alias declaration of the form `type Name TypeVar1 TypeVar2 = AliasedType`.\nIt expects the \"type\" keyword, parses the alias name and type variables, expects \"=\", skips newlines, and parses the aliased type expression.\nReturns `{:ok, %Ast.TypeAlias{}, remaining_tokens}` or an error tuple.","deps":["expect_keyword","parse_identifier","parse_many","expect_operator","skip_newlines","parse_type"]},{"code":"# Parse a type atom (used for application args)\n  def parse_type_atom(tokens) do\n    case tokens do\n      [%Token{type: :delimiter, value: \"{\"} | _] = toks ->\n        parse_record_type(toks)\n\n      [%Token{type: :identifier, value: name} | _] = toks ->\n        parse_qualified_identifier(toks)\n\n      [%Token{type: :delimiter, value: \"(\"} | rest] ->\n        with {:ok, type, rest} <- parse_type(rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \")\") do\n          {:ok, type, rest}\n        end\n\n      [%Token{type: :delimiter, value: \"[\"} | rest] ->\n        with {:ok, element_type, rest} <- parse_type(rest),\n             {:ok, _, rest} <- expect_delimiter(rest, \"]\") do\n          {:ok, %Ast.FunctionCall{function: \"[]\", arguments: [element_type]}, rest}\n        end\n\n      _ ->\n        {:error, \"Expected type atom\"}\n    end\n  end","name":"parse_type_atom","description":"Parses an atomic type expression, used as arguments in type applications.\nAn atom can be a record type, a qualified identifier, a parenthesized type, or a list type.\nIt checks the leading token to dispatch to the appropriate parser.\nReturns `{:ok, type_atom_ast, remaining_tokens}` or an error tuple.","deps":["parse_record_type","parse_qualified_identifier","parse_type","expect_delimiter"]},{"code":"# ────────────────────────────────────────────────────\n  # UPDATED PARSERS\n  # ────────────────────────────────────────────────────\n  # Supports superclass constraints:  \n  #   class (Applicative m, Bind m) <= Monad m where …\n  defp parse_type_class(tokens) do\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"class\") do\n      {tokens, _constraints} = skip_superclass_constraints(tokens)\n\n      with {:ok, class_name, tokens} <- parse_identifier(tokens),\n           {:ok, type_vars, tokens} <- parse_many(&parse_identifier/1, tokens),\n           {:ok, _, tokens} <- expect_keyword(tokens, \"where\"),\n           {:ok, methods, tokens} <- parse_many(&parse_type_signature/1, tokens) do\n        {:ok,\n         %Ast.TypeClass{\n           name: class_name.name,\n           type_vars: Enum.map(type_vars, & &1.name),\n           methods: methods\n         }, tokens}\n      end\n    end\n  end","name":"parse_type_class","description":"Parses a type class declaration of the form `class [Constraints <=] ClassName TypeVar1 TypeVar2 where Methods`.\nIt expects the \"class\" keyword, optionally skips superclass constraints, parses the class name and type variables, expects \"where\", and parses zero or more method type signatures.\nReturns `{:ok, %Ast.TypeClass{}, remaining_tokens}`.","deps":["expect_keyword","skip_superclass_constraints","parse_identifier","parse_many","parse_type_signature"]},{"code":"# Handles both named and unnamed instances, with optional constraints:\n  #   instance showString :: Show String where …\n  #   instance (Eq a) <= Show a where …\n  defp parse_type_class_instance(tokens) do\n    with {:ok, _, tokens} <- expect_keyword(tokens, \"instance\") do\n      tokens = drop_newlines(tokens)\n\n      case tokens do\n        # ── Named instance – starts with ident followed by '::' ──\n        [%Token{type: :identifier, value: inst_name}, %Token{type: :operator, value: \"::\"} | rest] ->\n          rest = drop_instance_constraints(rest)\n\n          with {:ok, type_ast, tokens} <- parse_type(rest),\n               {:ok, _, tokens} <- expect_keyword(tokens, \"where\"),\n               {:ok, methods, tokens} <- parse_many(&parse_function_declaration/1, tokens) do\n            class_name =\n              case type_ast do\n                %Ast.FunctionCall{function: %Ast.Identifier{name: cn}} -> cn\n                %Ast.Identifier{name: cn} -> cn\n                _ -> inst_name\n              end\n\n            {:ok,\n             %Ast.TypeClassInstance{\n               class_name: class_name,\n               type: type_ast,\n               methods: methods\n             }, tokens}\n          end\n\n        # ── Unnamed instance – old syntax: Class Type where … ──\n        _ ->\n          tokens = drop_instance_constraints(tokens)\n\n          with {:ok, class_name, tokens} <- parse_identifier(tokens),\n               {:ok, type_ast, tokens} <- parse_type(tokens),\n               {:ok, _, tokens} <- expect_keyword(tokens, \"where\"),\n               {:ok, methods, tokens} <- parse_many(&parse_function_declaration/1, tokens) do\n            {:ok,\n             %Ast.TypeClassInstance{\n               class_name: class_name.name,\n               type: type_ast,\n               methods: methods\n             }, tokens}\n          end\n      end\n    end\n  end","name":"parse_type_class_instance","description":"Parses a type class instance declaration.\nIt handles two forms: named instances (`instance name :: Type where ...`) and unnamed instances (`instance [Constraints <=] Class Type where ...`).\nIt expects the \"instance\" keyword, drops newlines, checks for the \"::\" pattern for named instances, drops constraints, parses the instance type (and class name implicitly for unnamed), expects \"where\", and parses the instance methods (function declarations).\nReturns `{:ok, %Ast.TypeClassInstance{}, remaining_tokens}`.","deps":["expect_keyword","drop_newlines","drop_instance_constraints","parse_type","parse_many","parse_function_declaration","parse_identifier"]},{"code":"# Type signature parsing\n  defp parse_type_signature(tokens) do\n    tokens = drop_newlines(tokens)\n\n    with {:ok, name, tokens} <- parse_identifier(tokens),\n         {:ok, _, tokens} <- expect_operator(tokens, \"::\"),\n         {:ok, type, tokens} <- parse_type(tokens) do\n      {:ok, %Ast.TypeSignature{name: name.name, type_vars: [], constraints: [], type: type},\n       tokens}\n    else\n      other -> other\n    end\n  end","name":"parse_type_signature","description":"Parses a standalone type signature declaration of the form `name :: Type`.\nIt expects an identifier for the name, then \"::\", and parses the type expression.\nReturns `{:ok, %Ast.TypeSignature{}, remaining_tokens}` or an error tuple.","deps":["drop_newlines","parse_identifier","expect_operator","parse_type"]},{"code":"defp parse_type_term(tokens) do\n    parse_any(\n      [\n        &parse_record_type/1,\n        &parse_list_type/1,\n        &parse_tuple_type/1,\n        &parse_basic_type/1\n      ],\n      tokens\n    )\n  end","name":"parse_type_term","description":"Parses a single \"term\" in a type expression, which can be a record type, list type, tuple type, or basic type (identifier or application).\nUses `parse_any` to try multiple specific type term parsers.\nReturns `{:ok, type_ast, remaining_tokens}` or an error tuple if none succeed.","deps":["parse_any","parse_record_type","parse_list_type","parse_tuple_type","parse_basic_type"]},{"code":"defp take_body(tokens, acc, indent) do\n    case tokens do\n      [] ->\n        {Enum.reverse(acc), []}\n\n      [%Token{type: :newline} = nl | rest] ->\n        rest = skip_newlines(rest)\n\n        clause_start = clause_start?(rest)\n\n        case rest do\n          # ❶ plain dedent – always end the body\n          [%Token{column: col} | _] = next when col < indent ->\n            {Enum.reverse(acc), next}\n\n          # ❷ same-column clause start – also end the body\n          [%Token{column: col} | _] = next when col == indent and clause_start ->\n            {Enum.reverse(acc), next}\n\n          # ❸ otherwise keep accumulating\n          _ ->\n            take_body(rest, [nl | acc], indent)\n        end\n\n      [tok | rest] ->\n        take_body(rest, [tok | acc], indent)\n    end\n  end","name":"take_body","description":"Collects tokens that form the body of a case clause, based on indentation.\nIt accumulates tokens until it encounters a newline followed by tokens that are dedented relative to the clause's starting indentation, or a newline followed by tokens at the same indentation that look like the start of a new clause.\nReturns `{body_tokens, remaining_tokens_after_body}`.","deps":["skip_newlines","clause_start?","take_body"]}]